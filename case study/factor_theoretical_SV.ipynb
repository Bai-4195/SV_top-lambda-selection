{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dda361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import time\n",
    "import random\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94952160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the model parameters\n",
    "class bayesian_network_posterior:\n",
    "    def __init__(self, the_R, tau2_R, kap_R, lam_R, mu, num_state, num_action, n_time, beta, v2):\n",
    "        self.the_R = the_R\n",
    "        self.tau2_R = tau2_R\n",
    "        self.kap_R = kap_R\n",
    "        self.lam_R = lam_R\n",
    "        self.num_nodes = (num_state + num_action) * n_time\n",
    "        self.num_state = num_state\n",
    "        self.num_action = num_action\n",
    "        self.mu = mu\n",
    "        self.beta = beta\n",
    "        self.v2 = v2\n",
    "        self.n_time = n_time\n",
    "\n",
    "    def posterior_sample(self, size=1, useFixed = True):\n",
    "        p_beta = np.zeros(shape=(self.num_nodes,self.num_nodes, size))\n",
    "        p_v2 = np.zeros(shape=(self.num_nodes, size))\n",
    "        for i in range(self.num_nodes):\n",
    "            for j in range(self.num_nodes):\n",
    "                if self.tau2_R[i, j] != 0:\n",
    "                    p_beta[i, j, ] = np.random.normal(loc=self.the_R[i,j], scale=np.sqrt(self.tau2_R[i,j]), size=size)\n",
    "            gamma_rate = self.lam_R[i] / 2\n",
    "            p_v2[i,] = 1 / np.random.gamma(shape=self.kap_R[i] / 2, scale=1/gamma_rate, size=size)\n",
    "        if useFixed:\n",
    "            p_beta = self.beta\n",
    "            p_v2 = self.v2\n",
    "        return (p_beta, p_v2, self.mu)\n",
    "\n",
    "class bayesian_network:\n",
    "    def __init__(self, mu, beta, v2, num_action, num_state, n_time, normalized = True, sample_mean=None, sample_sd=None):\n",
    "        self.n_time = n_time\n",
    "        if normalized:\n",
    "            self.sample_mean = sample_mean\n",
    "            self.sample_sd = sample_sd\n",
    "            self.normalized = True\n",
    "        self.initial_state_full = np.array([0.05, 0.00, 0.00, 30.00, 5.00,0.7])\n",
    "        if num_state == 4:\n",
    "            self.initial_state_base = self.initial_state_full[[0, 1, 3, 4, 5]]\n",
    "        if num_state == 5:\n",
    "            self.initial_state_base = self.initial_state_full\n",
    "        self.mu = mu\n",
    "        self.v2 = v2\n",
    "        self.beta = beta\n",
    "        self.num_action = num_action\n",
    "        self.num_state = num_state\n",
    "        self.n_factor = num_action + num_state\n",
    "        self.beta_state = np.zeros(shape=(n_time, num_state, num_state)) # s -> s\n",
    "        self.beta_action = np.zeros(shape=(n_time, num_action, num_state)) # a -> s\n",
    "        for i in range(n_time-1):\n",
    "            self.beta_state[i,:,:] = beta[(self.n_factor * (i+1) - num_state):(self.n_factor * (i+1)), (self.n_factor * (i + 2) - num_state): (self.n_factor * (i + 2))]\n",
    "            self.beta_action[i,:,:] = beta[(self.n_factor * i):(self.n_factor * i + self.num_action), (self.n_factor * (i + 2) - num_state):(self.n_factor * (i + 2))]\n",
    "        self.mu_a = []\n",
    "        for i in range(self.n_time):\n",
    "            temp_list = []\n",
    "            for j in range(self.num_action):\n",
    "                temp_list.append(self.mu[i * self.n_factor + j])\n",
    "            self.mu_a.append(temp_list)\n",
    "\n",
    "    def initial_state_generator(self, scale=10):\n",
    "        init_states = self.initial_state_base + np.abs(np.random.normal(0, np.array(self.initial_state_base)/scale + 0.01))\n",
    "        init_states = init_states[[0,1,3,4,5]] # init_states[:-1] * init_states[-1]\n",
    "        self.initial_state = (init_states - self.sample_mean[(self.n_factor - self.num_state):self.n_factor]) / self.sample_sd[(self.n_factor - self.num_state):self.n_factor]\n",
    "\n",
    "    def rescale_action(self, action, t, scale_method = \"standard\"):\n",
    "        if not self.normalized:\n",
    "            return action\n",
    "        if scale_method == \"standard\":\n",
    "            return self.sample_sd[(self.n_factor * t):(self.n_factor * t + self.num_action)] * action + self.sample_mean[(self.n_factor * t):(self.n_factor * t + self.num_action)]\n",
    "        else:\n",
    "            return self.sample_sd[(self.n_factor * t):(self.n_factor * t + self.num_action)] * action\n",
    "\n",
    "    def rescale_state(self, state, t, scale_method = \"standard\"):\n",
    "        if not self.normalized:\n",
    "            return state\n",
    "        if scale_method == \"standard\":\n",
    "            return self.sample_sd[(self.n_factor * (t+1) - self.num_state):(self.n_factor * (t+1))] * state + self.sample_mean[(self.n_factor * (t+1) - self.num_state):(self.n_factor * (t+1))]\n",
    "        else:\n",
    "            return self.sample_sd[(self.n_factor * (t+1) - self.num_state):(self.n_factor * (t+1))] * state\n",
    "        \n",
    "beta_gibbs = pd.read_csv('data/beta_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "v2_gibbs = pd.read_csv('data/v2_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None,\n",
    "                        dtype=np.float64)\n",
    "the_R = pd.read_csv('data/the_R_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "tau2_R = pd.read_csv('data/tau2_R_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "kap_R = pd.read_csv('data/kap_R_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "lam_R = pd.read_csv('data/lam_R_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "mu = pd.read_csv('data/mu_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "sd = pd.read_csv('data/sd_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "bn_post = bayesian_network_posterior(the_R.to_numpy(), tau2_R.to_numpy(), kap_R.to_numpy(), lam_R.to_numpy(),\n",
    "                                         mu.to_numpy().flatten(), 5, 1, 36, beta_gibbs, v2_gibbs)\n",
    "# mua = np.array(mu.to_numpy().reshape(36, 6)[:, 0]).reshape(1, 36)\n",
    "# mus = np.array(mu.to_numpy().reshape(36, 6)[:, 1:]).reshape(5, 36)\n",
    "\n",
    "# 这个函数可以生成5个状态和5个状态之间的协方差矩阵，随机生成相关性矩阵，代表了H=36个周期\n",
    "def simulate(H = 36, nums = 5, seed = 1):\n",
    "    np.random.seed(seed)\n",
    "    V_mat = np.zeros((H*nums, H*nums))\n",
    "    mat = (2*np.random.rand((H-1)*nums, (H-1)*nums)-1)/5\n",
    "    V_mat[nums*1:nums*H, nums*1:nums*H] = mat.dot(mat.T)\n",
    "    return V_mat\n",
    "\n",
    "def new_simulate(H = 36, nums = 5, seed = 1):\n",
    "    np.random.seed(seed)\n",
    "    V_mat = np.zeros((H*nums, H*nums))\n",
    "    mat = (2*np.random.rand(H*nums, H*nums)-1)/5\n",
    "    V_mat[nums*0:nums*H, nums*0:nums*H] = mat.dot(mat.T)\n",
    "    return V_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e8dde1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "nums = 5\n",
    "H = 4\n",
    "# 只需要生成一个样本，用来当作真实的参数\n",
    "ssize1 = 1\n",
    "p_beta, p_v2, mu0 = bn_post.posterior_sample(ssize1, useFixed=False)\n",
    "v_mat = simulate(H=H, seed = 4) # 这个可以得到一个随机的random factor的协方差矩阵,定义为多元正态分布，均值为0\n",
    "mu = pd.read_csv('data/mu_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64) \n",
    "s1 = np.array([0.05,0,30,5,0.7])\n",
    "theta = np.load('theta.npy')\n",
    "\n",
    "# b_r 和 c_r是组成奖励函数的参数\n",
    "b_r = np.repeat(-534.52, H)\n",
    "c_r = np.zeros((5, H))\n",
    "c_r[1, H-1] = 1.29\n",
    "\n",
    "\n",
    "beta = p_beta[:,:,0]\n",
    "v2 = p_v2[:,0]\n",
    "bn = bayesian_network(mu0, beta, v2, 1, 5, 36, True, mu, sd.to_numpy().flatten())\n",
    "# mu_a mu_s beta_a beta_s theta_0事先就可以确定下来，不需要在过程中计算\n",
    "mua = np.array(bn.mu_a).reshape(1, 36)\n",
    "mus = np.array(bn.mu.reshape(36, 6)[:,1:]).reshape(5,36)\n",
    "betas = np.zeros((5, 5, 36))\n",
    "for i in range(36):\n",
    "    betas[:,:,i] = bn.beta_state[i,:,:]\n",
    "betaa = np.transpose(bn.beta_action.reshape(36,5))\n",
    "\n",
    "# 为了减少维数，进行截断\n",
    "mua = mua[:,:H]\n",
    "mus = mus[:,:H]\n",
    "betas = betas[:,:,:H]\n",
    "betaa = betaa[:,:H]\n",
    "theta = theta[:,:H-1]\n",
    "\n",
    "theta_0 = np.concatenate((theta, np.zeros((nums, 1))), axis = 1)\n",
    "\n",
    "permutations = itertools.permutations([i for i in range(H*nums)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64fdaf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一些基本的函数\n",
    "def reward(b_r, c_r, a, s):\n",
    "    return np.dot(b_r,a) + np.dot(c_r, s)\n",
    "\n",
    "def policy(mua, mus, theta, s):\n",
    "    return mua + np.dot(theta, s - mus)\n",
    "\n",
    "# 这里的转移函数暂时不考虑随机因子\n",
    "def transition(mus1, mus, mua, betas, betaa,s, a):\n",
    "    return mus1 + np.dot(betas, s - mus) + betaa*(a - mua)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a591a46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于计算理论上真实的SV\n",
    "def R2(tt,t):\n",
    "    global betas,betaa,theta_0,nums\n",
    "    R = np.eye(nums)\n",
    "    while tt <= t:\n",
    "        # betas 是5*5*36\n",
    "        tmp = betas[:,:, tt] + np.outer(betaa[:,tt], theta_0[:,tt])\n",
    "        R = np.dot(R,tmp)\n",
    "        tt = tt+1\n",
    "    return R\n",
    "\n",
    "alpha = np.zeros((H,nums))\n",
    "for t in range(H):\n",
    "    alpha[t] = np.dot(b_r[t], theta_0[:,t]) + c_r[:,t]\n",
    "\n",
    "\n",
    "def R1(t):\n",
    "    global H,alpha\n",
    "    R = 0\n",
    "    for i in range(t,H):\n",
    "        R += np.dot(alpha[i,:], R2(t, i-1))\n",
    "    return R\n",
    "\n",
    "# 接下来用一个列表填充关于R的内容\n",
    "R = []\n",
    "for t in range(H):\n",
    "    R.append(R1(t))\n",
    "R = np.concatenate(R) # 一共5*36个随机因子，组成对应180个R\n",
    "\n",
    "\n",
    "# 接下来定义价值函数，注意180个随机因子的协方差矩阵是v_mat，假设来自于均值为0的正态\n",
    "# 给定一个索引的集合，然后用来构建相对应的R和协方差矩阵\n",
    "def value_function(subset):\n",
    "    # 对这些随机变量索引的集合排序\n",
    "    global H,nums,R,v_mat\n",
    "    all_list = [i for i in range(H*nums)]\n",
    "    u_list = sorted(subset)\n",
    "    neg_u_list = [item for item in all_list if item not in u_list]\n",
    "    R_u = []\n",
    "    R_neg = []\n",
    "    for i in range((H-1)*nums):\n",
    "        if i in u_list:\n",
    "            R_u.append(R[i])\n",
    "        else:\n",
    "            R_neg.append(R[i])\n",
    "    R_u = np.array(R_u)\n",
    "    R_neg = np.array(R_neg)\n",
    "    # 下面是协方差\n",
    "    length_u = len(R_u)\n",
    "    length_neg = len(R_neg)\n",
    "    sigma_u = np.zeros((length_u,length_u))\n",
    "    sigma_neg_u = np.zeros((length_neg, length_u))\n",
    "    # 先填写sigma u\n",
    "    for i in range(length_u):\n",
    "        for j in range(length_u):\n",
    "            sigma_u[i][j] = v_mat[u_list[i]][u_list[j]]\n",
    "    # 填写sigma -u u\n",
    "    for i in range(length_neg):\n",
    "        for j in range(length_u):\n",
    "            sigma_neg_u[i][j] = v_mat[neg_u_list[i]][u_list[j]]\n",
    "    if np.linalg.det(sigma_u) == 0: # 没有逆矩阵，使用伪逆\n",
    "        return (R_neg @ sigma_neg_u @ np.linalg.pinv(sigma_u) + R_u)@sigma_u@(R_neg @ sigma_neg_u @ np.linalg.pinv(sigma_u) + R_u)\n",
    "    else:  \n",
    "        return (R_neg @ sigma_neg_u @ np.linalg.inv(sigma_u) + R_u)@sigma_u@(R_neg @ sigma_neg_u @ np.linalg.inv(sigma_u) + R_u)\n",
    "\n",
    "def factorial_iterative(n):\n",
    "    result = 1\n",
    "    for i in range(1, n + 1):\n",
    "        result *= i\n",
    "    return result\n",
    "\n",
    "def get_elements_before(lst, element):\n",
    "    # 获取目标元素在列表中的索引\n",
    "    if element in lst:\n",
    "        index = lst.index(element)\n",
    "        # 返回索引之前的所有元素\n",
    "        return lst[:index]\n",
    "    else:\n",
    "        return []  # 如果目标元素不在列表中，返回空列表\n",
    "\n",
    "def shapley_value(i, subset):\n",
    "    global H,nums,permutations\n",
    "    res = 0\n",
    "    subset_before = get_elements_before(subset, i)\n",
    "    subset_include = subset_before + [i]\n",
    "    res += value_function(subset_include) - value_function(subset_before)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b874504c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time:  8.323248624801636\n",
      "[-1.22135191e-13 -1.55921498e-13 -1.15754517e-13 -2.84494206e-13\n",
      " -1.47679202e-13  7.34632105e+02  6.02774319e+02  1.23099787e+03\n",
      "  4.48865905e+02  1.69046244e+02  1.07690943e+03  1.49003168e+03\n",
      "  5.70475865e+02  2.33256786e+02  1.86785785e+03  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "s_time = time.time()\n",
    "shapley = np.zeros(H*nums)\n",
    "P = 1000\n",
    "for _ in range(P):\n",
    "    perm = [i for i in range(H*nums)]\n",
    "    random.shuffle(perm)\n",
    "    for i in range(H*nums):\n",
    "        shapley[i] += shapley_value(i, perm)\n",
    "shapley =shapley/P\n",
    "e_time = time.time()\n",
    "print('running time: ', e_time-s_time)\n",
    "print(shapley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70181feb",
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 使用ProcessPoolExecutor并行计算\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# map返回的是结果按顺序组成的列表\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(executor\u001b[38;5;241m.\u001b[39mmap(shapley_value, inputs))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 转换为numpy数组\u001b[39;00m\n\u001b[0;32m     11\u001b[0m results_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(results)\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\concurrent\\futures\\process.py:602\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[1;34m(iterable)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[0;32m    597\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;124;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;124;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 602\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m    603\u001b[0m         element\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    604\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m element:\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop())\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\concurrent\\futures\\_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fut\u001b[38;5;241m.\u001b[39mresult(timeout)\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "'''\n",
    "并行计算部分\n",
    "s_time = time.time()\n",
    "\n",
    "inputs = [i for i in range(H*nums)]\n",
    "\n",
    "# 使用ProcessPoolExecutor并行计算\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    # map返回的是结果按顺序组成的列表\n",
    "    results = list(executor.map(shapley_value, inputs))\n",
    "\n",
    "# 转换为numpy数组\n",
    "results_array = np.array(results)\n",
    "\n",
    "# 保存为npy格式\n",
    "np.save('true_shapley(15_factors).npy', results_array)\n",
    "\n",
    "print(results_array)\n",
    "\n",
    "e_time = time.time()\n",
    "print('running time: ', e_time-s_time)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cc3802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
